{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текстов на естественном языке: задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание набора данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот блокнот нужен для создания необработанного датасета для задачи классификации предложений по признаку авторства из оригинальных текстов. На выходе будет csv файл в формате: **\"Предложение\", \"автор\"**. \n",
    "\n",
    "Для создания датасета используются произведения: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Автор|Произведение|\n",
    "|---------  |-------|\n",
    "|А.П. Чехов | Сборник рассказов и повестей |\n",
    "|Ф.М. Достоевский| Сборник избранных сочинений |\n",
    "|Л.Н. Толстой| Самые популярные сочинения |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из репозитория https://github.com/d0rj/RusLit, в котором собраны тексты русских авторов из открытых источников."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт пакетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from nltk import tokenize, download\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо для токенизации предложения, достаточно вызвать на рабочей машине один раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dimab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Функция для загрузки и предобработки текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список предложений, длина которых более 5ти символов, так как более короткие, скорее всего, не несут полезной для определения авторства информации. Вообще говоря, эти предложения могут выражать, и выражать довольно ярко, стиль письма конкретного автора; однако в модели это не используется.\n",
    "\n",
    "Для улучшения работы токенизатора предложений проводятся замены некоторых комбинаций символов. Так, реплики будут отдельными от  речи автора предложениями, а проблема с кавычками должна быть решена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(filepath: str, min_char: int = 5) -> List[str]:\n",
    "    \n",
    "    text = str()\n",
    "    with open(filepath, 'r', encoding='utf8') as file:\n",
    "        text = file.read().replace('\\n', '. ')\n",
    "        text = text.replace('.”', '”.').replace('.\"', '\".').replace('?”', '”?').replace('!”', '”!')\n",
    "        text = text.replace('--', ' ').replace('. . .', '').replace('_', '')\n",
    "    \n",
    "    sentences = tokenize.sent_tokenize(text)    \n",
    "    sentences = [sentence for sentence in sentences if len(sentence) >= min_char]\n",
    "\n",
    "    return list(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создание набора предложений для каждого автора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chekhov = []\n",
    "for path in glob.glob('./input/Chekhov/*.txt'):\n",
    "    chekhov += split_text(path)\n",
    "    \n",
    "dostoevsky = []\n",
    "for path in glob.glob('./input/Dostoevsky/*.txt'):\n",
    "    dostoevsky += split_text(path)\n",
    "\n",
    "tolstoy = []\n",
    "for path in glob.glob('./input/Tolstoy/*.txt'):\n",
    "    tolstoy += split_text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Чехов : 21860  предложений\n",
      "Достоевский : 77817  предложений\n",
      "Толстой : 41769  предложений\n"
     ]
    }
   ],
   "source": [
    "text_dict = { 'Чехов': chekhov, 'Достоевский': dostoevsky, 'Толстой': tolstoy }\n",
    "\n",
    "for key in text_dict.keys():\n",
    "    print(key, ':', len(text_dict[key]), ' предложений')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый список содержит от 20535 до 77817 предложений. Чтобы в нашем наборе было равномерное распределение авторов, ограничим набор для каждого, к примеру, 18000 предложениями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Комбинируем предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина комбинированного и внутренне перемешанного списка: 54000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "max_len = 18_000\n",
    "\n",
    "names = [chekhov, dostoevsky, tolstoy]\n",
    "\n",
    "combined = []\n",
    "for name in names:\n",
    "    name = np.random.choice(name, max_len, replace = False)\n",
    "    combined += list(name)\n",
    "\n",
    "print('Длина комбинированного и внутренне перемешанного списка:', len(combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаём маркированный список"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом моменте важно указывать метки авторов (их имена) в том же порядке, что и на предыдущем шаге, иначе данные просто окажутся неверными. Пока что простой регулирующий это механизм в голову не приходит. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина маркированного списка: 54000\n"
     ]
    }
   ],
   "source": [
    "labels = ['Чехов'] * max_len + ['Достоевский'] * max_len + ['Толстой'] * max_len\n",
    "\n",
    "print('Длина маркированного списка:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод количества был нужен для дополнительного контроля за данными и их метками. Равенство говорит о том, что каждое предложение в нашем наборе данных будет иметь метку (правильную или не правильную - контролироваться должно было раньше). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайно перемешиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3)\n",
    "\n",
    "zipped = list(zip(combined, labels))\n",
    "random.shuffle(zipped)\n",
    "combined, labels = zip(*zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Экспорт получившегося набора данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = pd.DataFrame()\n",
    "out_data['text'] = combined\n",
    "out_data['author'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text       author\n",
      "0  Вы не знаете, как вы для меня важны и как вы м...      Толстой\n",
      "1  14)..    Однако эта часть мемуаров не была про...      Толстой\n",
      "2  Он прибежал из леса к опушке и, бледный, с рас...        Чехов\n",
      "3  — сказала мать, притворно сердито отталкивая д...      Толстой\n",
      "4  Вечер проектировался, однако же, запросто; ожи...  Достоевский\n",
      "                                                    text       author\n",
      "53995  Хвалить войну никто не решится.. – Но вы говор...  Достоевский\n",
      "53996                     Ты вот так и норовишь уколоть!        Чехов\n",
      "53997  – Давеча Гаврила Ардалионович Ивану Федоровичу...  Достоевский\n",
      "53998                  Армия не могла нигде поправиться.      Толстой\n",
      "53999  Минут через пять она еще раз повернулась, закр...        Чехов\n"
     ]
    }
   ],
   "source": [
    "print(out_data.head())\n",
    "print(out_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data.to_csv('author_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
